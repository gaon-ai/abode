name: Deploy DAGs to Airflow

on:
  push:
    branches:
      - main
    paths:
      - 'airflow/dags/**'
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup SSH
        env:
          SSH_PRIVATE_KEY: ${{ secrets.AIRFLOW_SSH_KEY }}
        run: |
          mkdir -p ~/.ssh
          echo "$SSH_PRIVATE_KEY" | base64 -d > ~/.ssh/airflow-key.pem || echo "$SSH_PRIVATE_KEY" > ~/.ssh/airflow-key.pem
          chmod 600 ~/.ssh/airflow-key.pem
          ssh-keyscan -H ${{ secrets.AIRFLOW_HOST }} >> ~/.ssh/known_hosts

      - name: Install rsync
        run: |
          sudo apt-get update -qq
          sudo apt-get install -y rsync

      - name: Deploy DAGs
        env:
          AIRFLOW_HOST: ${{ secrets.AIRFLOW_HOST }}
        run: |
          # Deploy to temp directory first
          rsync -avz --delete \
            -e "ssh -i ~/.ssh/airflow-key.pem -o StrictHostKeyChecking=no" \
            airflow/dags/ \
            ubuntu@${AIRFLOW_HOST}:/tmp/airflow-dags/

          # Move files with sudo
          ssh -i ~/.ssh/airflow-key.pem -o StrictHostKeyChecking=no ubuntu@${AIRFLOW_HOST} \
            'sudo rsync -a --delete /tmp/airflow-dags/ /opt/airflow/dags/ && sudo chown -R 50000:0 /opt/airflow/dags/'

          # Trigger DAG parsing
          ssh -i ~/.ssh/airflow-key.pem -o StrictHostKeyChecking=no ubuntu@${AIRFLOW_HOST} \
            'sudo docker compose -f /opt/airflow/docker-compose.yaml exec -T scheduler airflow dags reserialize'

          # Clean up deleted DAGs from database (DAGs that exist in DB but not in files)
          ssh -i ~/.ssh/airflow-key.pem -o StrictHostKeyChecking=no ubuntu@${AIRFLOW_HOST} \
            'sudo docker compose -f /opt/airflow/docker-compose.yaml exec -T scheduler bash -c "
              cd /opt/airflow/dags &&
              for dag_id in \$(airflow dags list --output table | tail -n +4 | awk \"{print \\\$1}\" | grep -v \"^===\"); do
                if [ ! -f \${dag_id}.py ] && [ ! -f */\${dag_id}.py ]; then
                  echo \"Deleting orphaned DAG: \$dag_id\"
                  airflow dags delete \$dag_id -y || true
                fi
              done
            "'

          echo "DAGs deployed successfully to ${AIRFLOW_HOST}"

      - name: Verify deployment
        env:
          AIRFLOW_HOST: ${{ secrets.AIRFLOW_HOST }}
        run: |
          ssh -i ~/.ssh/airflow-key.pem -o StrictHostKeyChecking=no ubuntu@${AIRFLOW_HOST} \
            'ls -la /opt/airflow/dags/'
